{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "# internal imports\n",
    "import tensorflow as tf\n",
    "\n",
    "from magenta.music import midi_io\n",
    "from magenta.music import musicxml_reader\n",
    "from magenta.music import note_sequence_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_midi(full_file_path):\n",
    "  \"\"\"Converts a midi file to a sequence proto.\"\"\"\n",
    "  try:\n",
    "    sequence = midi_io.midi_to_sequence_proto(\n",
    "        tf.gfile.FastGFile(full_file_path, 'rb').read())\n",
    "  except midi_io.MIDIConversionError as e:\n",
    "    tf.logging.warning(\n",
    "        'Could not parse MIDI file %s. It will be skipped. Error was: %s',\n",
    "        full_file_path, e)\n",
    "    return None\n",
    "  sequence.filename = full_file_path\n",
    "  sequence.id = note_sequence_io.generate_note_sequence_id(\n",
    "      sequence.filename, sequence.collection_name, 'midi')\n",
    "  tf.logging.info('Converted MIDI file %s.', full_file_path)\n",
    "#   print(sequence)\n",
    "  return sequence\n",
    "print('finish load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_hand_path = '/Users/mac/Desktop/TwoHands.mid'\n",
    "two_hand = convert_midi(two_hand_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Structure of Note:https://github.com/tensorflow/magenta/blob/master/magenta/protobuf/music.proto\n",
    "print(len(two_hand.notes))\n",
    "for i in range(10):\n",
    "    print(two_hand.notes[i])\n",
    "# print(res.tempos)\n",
    "# print(res.PitchName.F_FLAT_FLAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import midi\n",
    "# Instantiate a MIDI Pattern (contains a list of tracks)\n",
    "pattern = midi.Pattern()\n",
    "# Instantiate a MIDI Track (contains a list of MIDI events)\n",
    "track = midi.Track()\n",
    "# Append the track to the pattern\n",
    "pattern.append(track)\n",
    "# Instantiate a MIDI note on event, append it to the track\n",
    "on = midi.NoteOnEvent(tick=0, velocity=20, pitch=midi.G_3)\n",
    "track.append(on)\n",
    "# Instantiate a MIDI note off event, append it to the track\n",
    "off = midi.NoteOffEvent(tick=100, pitch=midi.G_3)\n",
    "track.append(off)\n",
    "# Add the end of track event, append it to the track\n",
    "eot = midi.EndOfTrackEvent(tick=1)\n",
    "track.append(eot)\n",
    "# Print out the pattern\n",
    "print(pattern)\n",
    "# Save the pattern to disk\n",
    "midi.write_midifile(\"example.mid\", pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import pickle\n",
    "from my_to_midi import *\n",
    "from sequence_example_lib import *\n",
    "import copy\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_events(x):\n",
    "    return np.argmax(x, axis=1)\n",
    "def to_real_length(x):\n",
    "    while(x[len(x)-1]==0):\n",
    "        x.pop()\n",
    "    # delete the last note along with padded zeros\n",
    "    x.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_example_to_real_inputs(sequence_example_path):\n",
    "    # train\n",
    "    sequence_example_file = sequence_example_path\n",
    "    sequence_example_file_paths = tf.gfile.Glob(\n",
    "        os.path.expanduser(sequence_example_file))\n",
    "    start_time = time.time()\n",
    "    inputs, labels, lengths = get_numpy_from_tf_sequence_example( input_size=259,\n",
    "                                        sequence_example_file_paths = sequence_example_file_paths,\n",
    "                                        shuffle = False)\n",
    "    print('Time:',time.time() - start_time)\n",
    "    print('inputs shape',inputs.shape)\n",
    "    print('inputs type',type(inputs))\n",
    "    input_events = []\n",
    "    for i in inputs:\n",
    "        input_events.append(to_events(i))\n",
    "    real_inputs = []\n",
    "    for i in input_events:\n",
    "        d = []\n",
    "        d = list(i)\n",
    "        to_real_length(d)\n",
    "        real_inputs.append(d)\n",
    "    return real_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start(events):\n",
    "    for i, event in enumerate(events):\n",
    "        if event==2:\n",
    "            return events[i:len(events)]\n",
    "def get_melody(events):\n",
    "    ret = []\n",
    "    for i, event in enumerate(events):\n",
    "        if event==2:\n",
    "            pass\n",
    "            #ret.append(event)\n",
    "        else:\n",
    "            if i>0 and events[i-1]==2:\n",
    "                ret.append([event])\n",
    "    return ret\n",
    "def get_accomp(events):\n",
    "    ret = []\n",
    "    for i, event in enumerate(events):\n",
    "        if event==2:\n",
    "            pass\n",
    "            #ret.append(event)\n",
    "        else:\n",
    "            if i>0 and events[i-1]==2:\n",
    "                for j in range(i+1, len(events)):\n",
    "                    if events[j]==2 or j==len(events)-1:\n",
    "                        ret.append(events[i+1:j+1])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_example_to_events_file(sequence_example_path, output_dir, name):\n",
    "    real_inputs = sequence_example_to_real_inputs(sequence_example_path)\n",
    "    \n",
    "    melodys = []\n",
    "    accomps = []\n",
    "    \n",
    "    for i, real_input in enumerate(real_inputs):\n",
    "        events = get_start(real_input)\n",
    "        melody = get_melody(events)\n",
    "        accomp = get_accomp(events)\n",
    "        melodys.append(melody)\n",
    "        accomps.append(accomp)\n",
    "        if i==0:\n",
    "            print(events)\n",
    "            print(melody)\n",
    "            print(accomp)\n",
    "    \n",
    "    melody_path = os.path.join(output_dir, name)+'_melody.pkl'\n",
    "    with open(melody_path,'wb') as mf:   #pickle只能以二进制格式存储数据到文件\n",
    "        mf.write(pickle.dumps(melodys))   #dumps序列化源数据后写入文件\n",
    "        mf.close()\n",
    "\n",
    "    accomp_path = os.path.join(output_dir, name)+'_accomp.pkl'\n",
    "    with open(accomp_path,'wb') as af:   #pickle只能以二进制格式存储数据到文件\n",
    "        af.write(pickle.dumps(accomps))   #dumps序列化源数据后写入文件\n",
    "        af.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_melody_and_accompaniment(sequence_example_dir, output_dir, name):\n",
    "    train_path = os.path.join(sequence_example_dir, \"training_poly_tracks.tfrecord\")\n",
    "    sequence_example_to_events_file(train_path, output_dir, name+\"_train\")\n",
    "    eval_path = os.path.join(sequence_example_dir, \"eval_poly_tracks.tfrecord\")\n",
    "    sequence_example_to_events_file(eval_path, output_dir, name+\"_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting: /Users/mac/Desktop/Bach/ Bach\n",
      "INFO:tensorflow:Counting records in /Users/mac/Desktop/Bach/training_poly_tracks.tfrecord.\n",
      "INFO:tensorflow:Total records: 1998\n",
      "INFO:tensorflow:[<tf.Tensor 'ParseSingleSequenceExample/ParseSingleSequenceExample:0' shape=(?, 259) dtype=float32>, <tf.Tensor 'ParseSingleSequenceExample/ParseSingleSequenceExample:1' shape=(?,) dtype=int64>, <tf.Tensor 'strided_slice:0' shape=() dtype=int32>]\n",
      "inputs (1998, 2395, 259) <class 'numpy.ndarray'> [ 0  2  2 71  2 70  2 71  2 73]\n",
      "labels (1998, 2395) <class 'numpy.ndarray'> [ 2  2 71  2 70  2 71  2 73  2]\n",
      "Time: 10.879290103912354\n",
      "inputs shape (1998, 2395, 259)\n",
      "inputs type <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0c5309e21f89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagenta_datasets_dirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagenta_datasets_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Converting:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mto_melody_and_accompaniment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/Users/mac/Desktop/makedataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-db88c39568dd>\u001b[0m in \u001b[0;36mto_melody_and_accompaniment\u001b[0;34m(sequence_example_dir, output_dir, name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_melody_and_accompaniment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_example_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_example_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training_poly_tracks.tfrecord\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msequence_example_to_events_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0meval_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_example_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eval_poly_tracks.tfrecord\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msequence_example_to_events_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-384a20d38421>\u001b[0m in \u001b[0;36msequence_example_to_events_file\u001b[0;34m(sequence_example_path, output_dir, name)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmelody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_melody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0maccomp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mmelodys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0maccomps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccomp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b67f9785c798>\u001b[0m in \u001b[0;36mget_accomp\u001b[0;34m(events)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                         \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "magenta_datasets_dirs = [\n",
    "    '/Users/mac/Desktop/Bach/'\n",
    "    ]\n",
    "magenta_datasets_names = [\n",
    "    'Bach'\n",
    "    ]\n",
    "for dataset_dir, dataset_name in zip(magenta_datasets_dirs, magenta_datasets_names):\n",
    "    print(\"Converting:\", dataset_dir, dataset_name)\n",
    "    to_melody_and_accompaniment(dataset_dir, \"/Users/mac/Desktop/makedataset\", dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
